{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sys.path.insert(0, '../functions/')\n",
    "\n",
    "import preprocess_data\n",
    "import train_test_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [00:03, 35.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (398, 24, 269)\n",
      "Test shape: (107, 24, 269)\n",
      "Balanced Train: True\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(preprocess_data)\n",
    "\n",
    "timeframe = \"1d\"\n",
    "data = pd.read_csv(f\"../data/BTC_EUR-{timeframe}.csv\")\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='ms')\n",
    "data.set_index(keys='Timestamp', inplace=True)\n",
    "\n",
    "shift_days = 10\n",
    "window = 24\n",
    "value_to_predict = 'Close'\n",
    "\n",
    "train_x, val_x, test_x, train_y, val_y, test_y = preprocess_data.preprocess_data(data, k=shift_days, column=value_to_predict, window=window)\n",
    "\n",
    "print('Train shape: {}\\nTest shape: {}\\nBalanced Train: {}'\n",
    "    .format(train_x.shape, test_x.shape, train_y.sum() == train_x.shape[0]/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(train_test_models)\n",
    "\n",
    "num_nets = 3\n",
    "\n",
    "model = list()\n",
    "for i in range(num_nets):\n",
    "    model.append(train_test_models.train_model(net=i, \n",
    "                                        train_data=(train_x, train_y), \n",
    "                                        batch_size=128, \n",
    "                                        epochs=50, \n",
    "                                        activation=None, \n",
    "                                        optimizer='adam', \n",
    "                                        loss='binary_crossentropy',\n",
    "                                        verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "for i in range(3):\n",
    "    tf.keras.utils.plot_model(\n",
    "        model[i], to_file=f'../models/model{i}.png', show_shapes=True, show_dtype=False,\n",
    "        show_layer_names=True, rankdir='TB', expand_nested=False, dpi=300,\n",
    "        layer_range=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buys: 1703, Holds: 1690\n",
      "True Buys: 827, False Buys: 809, True Holds: 894, False Holds: 863\n",
      "Accuracy: 0.5072\n",
      "Buys: 1703, Holds: 1690\n",
      "True Buys: 770, False Buys: 667, True Holds: 1036, False Holds: 920\n",
      "Accuracy: 0.5323\n",
      "Buys: 1703, Holds: 1690\n",
      "True Buys: 837, False Buys: 766, True Holds: 937, False Holds: 853\n",
      "Accuracy: 0.5228\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_nets):\n",
    "    train_test_models.test_model(model[i], test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extractors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12578, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list()\n",
    "features_x = list()\n",
    "for i in range(num_nets):\n",
    "    features.append(keras.Model(\n",
    "        inputs=model[i].inputs, \n",
    "        outputs=model[i].layers[-4].output\n",
    "    ))\n",
    "    features_x.append(features[i](train_x).numpy())\n",
    "\n",
    "features_conc = np.concatenate((features_x), axis=1)\n",
    "features_conc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Best estimator found by grid search:\n",
      "SVC(C=0.01, class_weight='balanced', kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['rbf', 'linear','sigmoid']}\n",
    "classifier = GridSearchCV(svm.SVC(class_weight='balanced'), param_grid)\n",
    "classifier = classifier.fit(features_conc, train_y[:,0])\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(classifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buys: 1703, Holds: 1690\n",
      "True Buys: 794, False Buys: 703, True Holds: 1000, False Holds: 896\n",
      "Accuracy: 0.5287\n"
     ]
    }
   ],
   "source": [
    "test_features = list()\n",
    "\n",
    "for i in range(num_nets):\n",
    "    test_features.append(features[i](test_x).numpy())\n",
    "\n",
    "test_con = np.concatenate((test_features), axis =  1)\n",
    "\n",
    "y_hat = classifier.predict(test_con)\n",
    "\n",
    "buys = test_y.sum()\n",
    "holds = len(test_y)-test_y.sum()\n",
    "\n",
    "cm = confusion_matrix(test_y, y_hat)\n",
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "\n",
    "print('Buys: {:d}, Holds: {:d}'.format(buys, holds))\n",
    "print(\"True Buys: {:d}, False Buys: {:d}, True Holds: {:d}, False Holds: {:d}\".format(TP[0],FP[0],TN[0],FN[0]))\n",
    "print(\"Accuracy: {:.4f}\".format(np.count_nonzero(((y_hat == test_y[:,0])))/len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/train_x_15m.npy\", train_x)\n",
    "np.save(\"../data/train_y_15m.npy\", train_y)\n",
    "np.save(\"../data/test_x_15m.npy\", test_x)\n",
    "np.save(\"../data/test_y_15m.npy\", test_y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0a5ee20017f608eb697d8c474b538a3e5a4aa80dc9080d00b16b4ae1c90e7aa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
